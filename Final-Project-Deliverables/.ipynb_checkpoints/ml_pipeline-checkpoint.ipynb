{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import random\n",
    "import zipfile\n",
    "import bz2\n",
    "import gzip\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import cStringIO\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import cPickle as pickle\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "import pgdb_funcs as db\n",
    "\n",
    "# XXX add import error check\n",
    "# XXX add the ability to instantiate node with attributes using the node options propert\n",
    "# XXX add the ability for remote_loc to be /data\n",
    "# XXX make sure modules dont leak, return only the value in the output json\n",
    "# XXX make sure all modules have sufficient state to resume and/or propagate attributes\n",
    "# XXX run should verify that it gets the input_parameters it expects\n",
    "# XXX change istr_jsons to istr_json (singular) and same for ostr_jsons\n",
    "# Let parent add useless keys like \"features\" to the output on the way out (POST)\n",
    "# XXX must have separate output_json for PRE and POST\n",
    "# add topdown arhument to all invocations of walk_Files()\n",
    "# NOTE: libmagic doesn't work on 64 bit Windows, so this program cannot be run on a Windows host\n",
    "import magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Globals\n",
    "http_chunksize__ = 8192  # 8K chunks when downloading files via HTTP\n",
    "random_seed__ = 0\n",
    "throw_exceptions = True\n",
    "gunzip_blocksize_ = 1 << 16\n",
    "randint_limit = 1000000\n",
    "\n",
    "DPRINT_SILENT = -1\n",
    "DPRINT_ERROR = 1\n",
    "DPRINT_WARN = 2\n",
    "DPRINT_INFO = 3\n",
    "DPRINT_DEBUG = 4\n",
    "DPRINT_VERBOSE = 5\n",
    "\n",
    "# Must match above values\n",
    "dprint_levels = [-1,1,2,3,4,5]\n",
    "\n",
    "dprint_strs = {-1 : \"SILENT\", 1 : \"ERROR\", 2 : \"WARN\", 3 : \"INFO\", 4 : \"DEBUG\", 5 : \"VERBOSE\"}\n",
    "\n",
    "\n",
    "# valid values are \"dev\", \"prod\"\n",
    "version=\"dev\"\n",
    "\n",
    "if version == \"dev\":\n",
    "    dprint_mode = DPRINT_ERROR\n",
    "else:\n",
    "    dprint_mode = DPRINT_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(random_seed__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "class UtilException(Exception):\n",
    "    pass\n",
    "\n",
    "def safe_rmtree(path):\n",
    "    if not os.path.exists(path):\n",
    "        return\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    elif os.path.isfile(path):\n",
    "        os.remove(path)\n",
    "        \n",
    "def get_file_type(path, mime=True):\n",
    "    return magic.from_file(path,mime)\n",
    "        \n",
    "def debug_raise():\n",
    "    if throw_exceptions:\n",
    "        raise\n",
    "   \n",
    "# Log messages, available in \"prod\" and \"dev\" versions\n",
    "def dprint(mode, msg):\n",
    "    if mode is None:\n",
    "        debug_raise()\n",
    "    if mode <= dprint_mode:\n",
    "        sys.stdout.write(\"(\" + dprint_strs[mode] + \")\" + msg + \"\\n\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "# Trace messages for testing and development available in \"dev\" version only\n",
    "def tprint(msg):\n",
    "    if version != \"dev\":\n",
    "        return\n",
    "    sys.stdout.write(msg + \"\\n\")\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def walk_exception(oserror):\n",
    "    dprint(DPRINT_ERROR, \"Error encountered while walking with filesystem object: \" + oserror.filename)\n",
    "    raise oserror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# XXX should this inherit from Object ? (new style classes and what not)\n",
    "class MLRoot:\n",
    "    __metaclass__ = ABCMeta\n",
    "    db_password = None\n",
    "    db_host = \"localhost\"\n",
    "    db_port = \"5432\"\n",
    "    db_tmo = 40000 * 3600  # 40 hours\n",
    "    \n",
    "    # XXX is init required if it does nothing?\n",
    "    def __init__(self):\n",
    "        self.class_name = \"MLRoot\"\n",
    "        self.name = None   # set based on mountpoint path\n",
    "        self.parent = None\n",
    "        self.young_sib = None\n",
    "        self.old_sib = None\n",
    "        self.child = []\n",
    "        \n",
    "        # We need the remote location\n",
    "        input_data = {\"remote_loc\" : \"\"}\n",
    "        input_json = json.dumps(input_data)\n",
    "        # We output a status\n",
    "        output_data = {\"status\" : \"\"}\n",
    "        output_json = json.dumps(output_data)\n",
    "        \n",
    "        self.istr_jsons = input_json\n",
    "        self.ostr_jsons = output_json\n",
    "        \n",
    "    def do_mount(self, subtree, resource):\n",
    "        \n",
    "            # subtree name must start with \"/\"\n",
    "            if not subtree.startswith(\"/\"):\n",
    "                raise MLException()\n",
    "            \n",
    "            comps = subtree.split(\"/\")\n",
    "            # subtree is of the form /name/child/grandchild\n",
    "            # split results in\n",
    "            #    \"\", \"name\", \"child\", \"grandchild\"\n",
    "            # Even for leaf we will have at a minimum 2 components\n",
    "            #    \"\", \"name\"\n",
    "            if len(comps) < 3:\n",
    "                raise MLException()\n",
    "                \n",
    "            # First component is always the empty string\n",
    "            if comps[0] != \"\":\n",
    "                raise MLException()\n",
    "            # Second component is always self\n",
    "            self.name = comps[1]\n",
    "                \n",
    "            cname = comps[2]\n",
    "            if len(comps) == 3:  # My child in the subtree is a leaf, instantiate it\n",
    "                dprint(DPRINT_INFO, \"creating node: resource: \" + resource + \", mount_subtree: \" + subtree)\n",
    "                child = eval(resource + \"()\")\n",
    "                child.class_name = resource\n",
    "                child.name = cname\n",
    "                child.parent = self\n",
    "                old_sib = None\n",
    "                for c in self.child:\n",
    "                    old_sib = c\n",
    "                if not old_sib is None:\n",
    "                    child.old_sib = old_sib\n",
    "                    old_sib.young_sib = child\n",
    "                self.child.append(child)\n",
    "                return child\n",
    "            \n",
    "            # Our chilc is an internal. We assume that internal nodes are instantiated earlier in the\n",
    "            # mount table (as leaves) that their leaves. So the child must be on our list of instatiated\n",
    "            # children. It is a mount error otherwise\n",
    "            # XXX Make this error an error return rather than an exception\n",
    "            child = None\n",
    "            for c in self.child:\n",
    "                if c.name == cname:\n",
    "                    child = c\n",
    "                    break\n",
    "            if child is None:\n",
    "                raise MLException()\n",
    "                \n",
    "            subtree = \"/\" + \"/\".join(comps[2:])\n",
    "            return child.do_mount(subtree, resource)\n",
    " \n",
    "        \n",
    "    def mount(self, mount_spec):\n",
    "        # Make sure system is not already mounted\n",
    "        if len(self.child) != 0:\n",
    "            raise MLException()\n",
    "        # Don't allow mount() to be invoked on anybody other than root\n",
    "        if self.class_name != \"MLRoot\":\n",
    "            raise MLException()\n",
    "            \n",
    "        # XXX One restriction in the mount table is that the\n",
    "        # parent must appear as a leaf in the mount_table before\n",
    "        # a child appears as a leaf. Enforce this rule.\n",
    "        with open(mount_spec, \"rb\") as mfd:\n",
    "            json_str = mfd.read()\n",
    "            mount_tab = json.loads(json_str)\n",
    "            mtab_list = []\n",
    "            for line_dict in mount_tab:\n",
    "                comment = True\n",
    "                entry = {}\n",
    "                for k, v in line_dict.iteritems():\n",
    "                    if k == \"resource\" or k == \"mount_point\" or k == \"options\":\n",
    "                        comment = False\n",
    "                        entry[k] = v\n",
    "                if comment:\n",
    "                    continue\n",
    "                keys = entry.keys()\n",
    "                if not \"resource\" in keys or \"mount_point\" not in keys:\n",
    "                    raise MLException()\n",
    "                # XXX handle options\n",
    "                mtab_list.append(entry)\n",
    "        \n",
    "        for entry in mtab_list:\n",
    "            # No need to mount root, it is always present\n",
    "            if entry[\"resource\"] == \"MLRoot\":\n",
    "                root_mount = entry[\"mount_point\"]\n",
    "                continue\n",
    "            \n",
    "            # We need an absolute path rooted at /root\n",
    "            if not entry[\"mount_point\"].startswith(\"/\"):\n",
    "                raise MLException()\n",
    "            if not entry[\"mount_point\"].startswith(root_mount):\n",
    "                raise MLException()\n",
    "            self.do_mount(entry[\"mount_point\"], entry[\"resource\"])\n",
    "    \n",
    "    def do_umount(self):\n",
    "        if len(self.child) != 0:\n",
    "            child = self.child[0].do_umount()\n",
    "            del child\n",
    "        self.child = []\n",
    "        if not self.young_sib is None:\n",
    "            young_sib = self.young_sib.do_umount()\n",
    "            del young_sib\n",
    "            self.young_sib = None\n",
    "        \n",
    "        dprint(DPRINT_INFO, \"Freeing node: name: \" + self.name +\",class: \" + self.class_name)\n",
    "        self.class_name = None\n",
    "        self.name = None\n",
    "        if not self.old_sib is None:\n",
    "            self.old_sib.young_sib = None\n",
    "        \n",
    "        # XXX destroy or save state\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def umount(self):\n",
    "        # Don't allow mount() to be invoked on anybody other than root\n",
    "        if self.class_name != \"MLRoot\":\n",
    "            raise MLException()\n",
    "            \n",
    "        self.do_umount()\n",
    "        \n",
    "            \n",
    "    def do_print(self, parent_path):\n",
    "        if parent_path is None:\n",
    "            raise MLException()\n",
    "            \n",
    "        my_path = parent_path + \"/\" + self.name\n",
    "        dprint(DPRINT_DEBUG, self.name + \": path: \" + my_path)\n",
    "        \n",
    "        for c in self.child:\n",
    "            c.do_print(parent_path=my_path)\n",
    "            \n",
    "    def print_tree(self):\n",
    "        my_path = \"/\" + self.name\n",
    "        for c in self.child:\n",
    "            c.do_print(parent_path=my_path)\n",
    "   \n",
    "    def do_compile(self, istr_jsons):\n",
    "        \n",
    "        dprint(DPRINT_DEBUG,  \"do_compile: \" + self.name)\n",
    "        \n",
    "        if self.ostr_jsons is None:\n",
    "            raise MLEXception()\n",
    "            \n",
    "        # XXX for testing\n",
    "        input_data = json.loads(istr_jsons)\n",
    "        output_data = json.loads(self.ostr_jsons)\n",
    "        for k in output_data.keys():\n",
    "            input_data[k] = \"\"\n",
    "            \n",
    "        return json.dumps(input_data)\n",
    "    \n",
    "    def compile(self, istr_jsons):\n",
    "        dprint(DPRINT_DEBUG,  \"compile: \" + self.name)\n",
    "        if self.istr_jsons is None:\n",
    "            raise MLException()\n",
    "            \n",
    "        # * means I will take anything\n",
    "        dprint(DPRINT_VERBOSE, self.name + \" input_data jsons: \" + str(istr_jsons))\n",
    "        dprint(DPRINT_VERBOSE, self.name + \" istr_jsons: \" + str(self.istr_jsons))\n",
    "        \n",
    "        actual_input = json.loads(istr_jsons)\n",
    "        actual_keys = actual_input.keys()\n",
    "        \n",
    "        # Input should have everything we need (specified by input schema)\n",
    "        # We don't care if there is other data present in input\n",
    "        need_input = json.loads(self.istr_jsons)\n",
    "        for need_key in need_input.keys():\n",
    "               if not need_key in actual_keys:\n",
    "                    dprint(DPRINT_DEBUG, self.name + \" input_data jsons: \" + str(istr_jsons))\n",
    "                    dprint(DPRINT_DEBUG, self.name + \" istr_jsons: \" + str(self.istr_jsons))\n",
    "                    raise MLException()\n",
    "        \n",
    "        ostr_jsons = self.do_compile(istr_jsons)\n",
    "        \n",
    "        actual_output = json.loads(ostr_jsons)\n",
    "        actual_keys = actual_output.keys()\n",
    "       \n",
    "        # Output should have everything we want to output (specified by output schema)\n",
    "        # We don't care if there is other data present in output\n",
    "        need_output = json.loads(self.ostr_jsons)\n",
    "        for need_key in need_output.keys():\n",
    "            if not need_key in actual_keys:\n",
    "                dprint(DPRINT_DEBUG, self.name + \" output_data jsons: \" + str(ostr_jsons))\n",
    "                dprint(DPRINT_DEBUG, self.name + \" ostr_jsons: \" + str(self.ostr_jsons))\n",
    "                raise MLException()\n",
    "        \n",
    "        if len(self.child) != 0:\n",
    "            ostr_jsons = self.child[0].compile(ostr_jsons)\n",
    "        if not self.young_sib is None:\n",
    "            ostr_jsons = self.young_sib.compile(ostr_jsons)\n",
    "        \n",
    "        dprint(DPRINT_VERBOSE, self.name + \" ostr_jsons: \" + str(ostr_jsons))\n",
    "        return ostr_jsons\n",
    "    \n",
    "    def do_run(self, input_data, traversal):\n",
    "        \n",
    "        # XXX should we return input_data with status key ?\n",
    "        if traversal == \"POST\":\n",
    "            input_data[\"status\"] = \"SUCCESS\"\n",
    "            return input_data\n",
    "        \n",
    "        dprint(DPRINT_INFO, self.name + \": RUN: NULL_ACTION: traversal: \" + traversal)\n",
    "        \n",
    "        return input_data\n",
    "    \n",
    "    def run(self, save, resume=None, comps=[\"\"], resume_comps=None, state=None, run_state=None, input_data=None, traversal=\"PRE\"):\n",
    "        \n",
    "        if resume == \".\":\n",
    "            raise MLException('\".\" is currently not supported for resume')\n",
    "            \n",
    "        if self.class_name == \"MLRoot\" and not resume is None:\n",
    "            if state is None:\n",
    "                raise MLException()\n",
    "            if not isinstance(state, basestring):\n",
    "                raise MLException()\n",
    "            with open(state, \"r\") as ifd:\n",
    "                msg = \"Loading state pickle file: \" + state\n",
    "                dprint(DPRINT_INFO, msg)\n",
    "                tprint(msg)\n",
    "                state = pickle.load(ifd)\n",
    "                \n",
    "            resume_comps = resume.split(\"/\")\n",
    "            if resume_comps[0] != \"\":\n",
    "                raise MLEXception()\n",
    "            del resume_comps[0]\n",
    "            dup = state[0][1]\n",
    "            self.class_name = dup.class_name\n",
    "            self.name = dup.name\n",
    "            self.parent = dup.parent\n",
    "            self.young_sib = dup.young_sib\n",
    "            self.old_sib = dup.old_sib\n",
    "            self.child = dup.child\n",
    "            self.istr_jsons = dup.istr_jsons\n",
    "            self.ostr_jsons = dup.ostr_jsons\n",
    "            run_state = []\n",
    "        elif self.class_name == \"MLRoot\":\n",
    "            run_state = []\n",
    "            resume_comps = []\n",
    "        \n",
    "        \n",
    "        #if not resume is None:\n",
    "        if len(resume_comps) > 0:\n",
    "            msg = \"Restoring input_data for: \" + self.name\n",
    "            dprint(DPRINT_VERBOSE, msg)\n",
    "            tprint(msg)\n",
    "            input_data = state[0][2]\n",
    "            del state[0]\n",
    "            \n",
    "        \n",
    "        # Do runtime checks on inputs - input should conform to schema\n",
    "        need_json = json.loads(self.istr_jsons)\n",
    "        input_keys = input_data.keys()\n",
    "        \n",
    "        for need_key in need_json.keys():\n",
    "            if need_key not in input_keys:\n",
    "                dprint(DPRINT_ERROR, self.name + \": Runtime Exception: Input data does not conform to input schema.\")\n",
    "                dprint(DPRINT_ERROR, self.name + \": \" + json.dumps(input_data.keys()) + \",\" + self.istr_jsons)\n",
    "                raise MLException()\n",
    "    \n",
    "        #if not resume is None:\n",
    "        if len(resume_comps) > 0:\n",
    "            name = resume_comps[0]\n",
    "            if name == self.name:\n",
    "                del resume_comps[0]\n",
    "        \n",
    "        idx = len(comps)\n",
    "        comps.append(self.name)\n",
    "        path = \"/\".join(comps)\n",
    "        dprint(DPRINT_INFO, \"Saving input state for: \" + self.name + \", path: \" + path)\n",
    "        run_state.append((path, copy.deepcopy(self), copy.deepcopy(input_data)))\n",
    "        \n",
    "        #if resume is None or len(resume_comps) == 0:\n",
    "        if len(resume_comps) == 0:\n",
    "            msg = \"Running do_run for: \" + self.name\n",
    "            dprint(DPRINT_DEBUG, msg)\n",
    "            tprint(msg)\n",
    "            input_data = self.do_run(input_data, \"PRE\")\n",
    "        #elif not resume is None:\n",
    "        else:\n",
    "            if len(state) > 2 and self.name in state[2][0]:\n",
    "                self.child = []\n",
    "                child = state[2][1]\n",
    "                self.child.append(child)\n",
    "                child.parent = self\n",
    "                msg = \"Created child: \" + child.name + \" for: \" + self.name\n",
    "                dprint(DPRINT_DEBUG, msg)\n",
    "                tprint(msg)\n",
    "            msg = \"Restoring output_data for: \" + self.name\n",
    "            dprint(DPRINT_DEBUG, msg)\n",
    "            tprint(msg)\n",
    "            input_data = state[0][2]\n",
    "            del state[0]\n",
    "            \n",
    "        dprint(DPRINT_INFO, \"Saving output state for: \" + self.name + \", path: \" + path)\n",
    "        run_state.append((path, copy.deepcopy(self), copy.deepcopy(input_data)))\n",
    "        if len(self.child) != 0:\n",
    "            input_data = self.child[0].run(save, resume, comps, resume_comps, state, run_state, input_data, \"PRE\")\n",
    "        \n",
    "        comps.pop(idx)\n",
    "                \n",
    "        #if resume is None or len(resume_comps) == 0:\n",
    "        if len(resume_comps) == 0:\n",
    "            msg = \"Running do_run (POST) for: \" + self.name\n",
    "            dprint(DPRINT_DEBUG, msg)\n",
    "            tprint(msg)\n",
    "            input_data = self.do_run(input_data, \"POST\") \n",
    "        #elif not resume is None:\n",
    "        else:\n",
    "            msg = \"Restoring POST output_data for: \" + self.name\n",
    "            dprint(DPRINT_DEBUG, msg)\n",
    "            tprint(msg)\n",
    "            input_data = state[0][2]\n",
    "            del state[0]\n",
    "        \n",
    "        dprint(DPRINT_INFO, \"Saving POST state for: \" + self.name + \", path: \" + path)\n",
    "        run_state.append((path, copy.deepcopy(self), copy.deepcopy(input_data)))\n",
    "            \n",
    "        # At this point we have exhausted our children\n",
    "        #if not resume is None:\n",
    "        if len(resume_comps) > 0:\n",
    "            if self.name in resume_comps:\n",
    "                raise MLEXception()\n",
    "            elif len(state) > 0 and self.name in state[0][0]:\n",
    "                msg = \"Still have children in state: name=\" + self.name + \", state-path=\" + state[0][0]\n",
    "                dprint(DPRINT_ERROR, msg)\n",
    "                tprint(msg)\n",
    "                raise MLException()\n",
    "        \n",
    "        # Do POST once our subtree is complete\n",
    "        # Do runtime checks on outputs - output should conform to schema\n",
    "        \n",
    "        ostr_json = json.loads(self.ostr_jsons)\n",
    "        output_keys = input_data.keys()\n",
    "        \n",
    "        for ostr_key in ostr_json.keys():\n",
    "            if ostr_key not in output_keys:\n",
    "                dprint(DPRINT_ERROR, self.name + \": Runtime Exception: Output data does not conform to output schema.\")\n",
    "                dprint(DPRINT_ERROR, self.name + \": \" + json.dumps(input_data.keys()) + \",\" + self.ostr_jsons)\n",
    "                raise MLException()\n",
    "        \n",
    "        #if not resume is None and len(state) > 0:\n",
    "        if len(resume_comps) > 0:\n",
    "            if not len(state) > 0:\n",
    "                raise MLException()\n",
    "            path = state[0][0]\n",
    "            state_comps = path.split(\"/\")\n",
    "            if not self.class_name is MLRoot and self.parent.name == state_comps[-2]:\n",
    "                self.young_sib = state[0][1]\n",
    "                self.young_sib.old_sib = self\n",
    "                self.young_sib.parent = self.parent\n",
    "                self.parent.child.append(self.young_sib)\n",
    "                msg = \"Created younger_sibling: \" + self.young_sib.name + \" for: \" + self.name\n",
    "                dprint(DPRINT_DEBUG, msg)\n",
    "                tprint(msg)\n",
    "                \n",
    "        if not self.young_sib is None:\n",
    "            input_data = self.young_sib.run(save, resume, comps, resume_comps, state, run_state, input_data, \"PRE\")\n",
    "        \n",
    "        if self.class_name == \"MLRoot\" and save:\n",
    "            if state is None:\n",
    "                raise MLException()\n",
    "            if not isinstance(state, basestring):\n",
    "                raise MLException()\n",
    "            with open(state, \"wb\") as ofd:\n",
    "                pickle.dump(run_state, ofd, -1)\n",
    "            msg = \"Saved state pickle file: \" + state\n",
    "            dprint(DPRINT_INFO, msg)\n",
    "            tprint(msg)\n",
    "        return input_data\n",
    "    \n",
    "    # dict_json must be a json string for a dict. Only top level keys become property names\n",
    "    # all other embedded objects become a part of the property value\n",
    "    # Example:  {\"mygoofyprop\" : {\"myembedded_key\" : 123}}\n",
    "    #           becomes:   self.mygoofyprop = {\"myembedded_key\" : 123}\n",
    "    def do_setprop(self, comps, dict_json):\n",
    "        # Unconditional set (a parent set this property so we need to set it too)\n",
    "       \n",
    "        if comps is None:\n",
    "            for k, v in dict_json.iteritems():\n",
    "                exec(\"self.\" + k + \" = \" + str(v))\n",
    "            if len(self.child) != 0:\n",
    "                self.child[0].do_setprop(None, dict_json)\n",
    "            if not self.young_sib is None:\n",
    "                self.young_sib.do_setprop(None, dict_json)\n",
    "            return\n",
    "        \n",
    "        if len(comps) == 1 and comps[0] == self.name:\n",
    "            for k, v in dict_json.iteritems():\n",
    "                if isinstance(v, basestring):\n",
    "                    v = '\"\"\"' + v + '\"\"\"'\n",
    "                exec(\"self.\" + k + \" = \" + str(v))\n",
    "                \n",
    "            # Ask our children to unconditionally set the proprty\n",
    "            if len(self.child) != 0:\n",
    "                return self.child[0].do_setprop(None, dict_json)\n",
    "            \n",
    "            return\n",
    "        elif comps[0] == self.name:\n",
    "            # There is more than 1 component left\n",
    "            if len(self.child) != 0:\n",
    "                return self.child[0].do_setprop(comps[1:], dict_json)\n",
    "        elif not self.young_sib is None:\n",
    "            # It not us or our child subtree, pass it on to sibling\n",
    "            return self.young_sib.do_setprop(comps, dict_json)\n",
    "        else:\n",
    "            raise MLException()\n",
    "        \n",
    "    \n",
    "    # Setting a property on a parent node sets it on all child nodes\n",
    "    def setprop(self, path, dict_json):\n",
    "        \n",
    "        comps = path.split(\"/\")\n",
    "        # comps[0] = \"\". The real name starts with component 1\n",
    "        del comps[0]\n",
    "        if comps[0] != self.name:\n",
    "            raise MLException()\n",
    "            \n",
    "        return self.do_setprop(comps, dict_json)\n",
    "    \n",
    "    # XXX add a note saying remount not being implemented as it is not useful\n",
    "        \n",
    "    # XXX have a stoy what you will do without exceptions to stop tree walk\n",
    "    # XXX talk about subclass able classes and not (suggested not subclassable classes)\n",
    "    \n",
    "    def do_walk(self, filepath, arg):\n",
    "        dprint(DPRINT_DEBUG, self.name + \": visiting file: \" + filepath)\n",
    "        return {\"stop\" : False}\n",
    "    \n",
    "    \n",
    "    def walk_files(self, pathroot, arg, topdown=True):\n",
    "         \n",
    "        isfile = os.path.isfile(pathroot)\n",
    "        isdir = os.path.isdir(pathroot)\n",
    "        \n",
    "        if not isfile and not isdir:\n",
    "            dprint(DPRINT_ERROR, \"Unknown FS entity: \" + pathroot)\n",
    "            raise MLException()\n",
    "                                         \n",
    "        try:\n",
    "            if isfile:\n",
    "                result = self.do_walk(pathroot, arg)\n",
    "            elif isdir:\n",
    "                stop = False\n",
    "                for dirpath, dirnames, filenames in os.walk(pathroot, topdown=topdown, onerror=walk_exception, followlinks=False):\n",
    "                    if stop:\n",
    "                        break\n",
    "                    for filename in filenames:\n",
    "                        filepath = os.path.join(dirpath, filename)\n",
    "                        result = self.do_walk(filepath, arg)\n",
    "                        if result[\"stop\"]:\n",
    "                            stop = True\n",
    "                            break\n",
    "        except:\n",
    "            # Use debug_raise() to reraise the original exception in debug mode\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "            \n",
    "    # data_name is a string and data is a 1-D or 2-D numpy array\n",
    "    def do_save(self, data_name, data):\n",
    "\n",
    "        if not isinstance(data_name, basestring):\n",
    "            raise MLException()\n",
    "        \n",
    "        if not isinstance(data, np.ndarray):\n",
    "            raise MLException()\n",
    "            \n",
    "        if data.ndim != 1 and data.ndim != 2:\n",
    "            raise MLException()\n",
    "            \n",
    "        DBobj = db.PGDBLib(MLRoot.db_password, MLRoot.db_host, MLRoot.db_port)\n",
    "        DBobj.open_db(MLRoot.db_tmo)\n",
    "    \n",
    "        rows = data.shape[0]\n",
    "            \n",
    "        fields = []\n",
    "        fields.append((\"example_id\", 'varchar', None))\n",
    "        fields.append((\"features\", \"varchar\", None))\n",
    "        constraint = 'CONSTRAINT pkey_' + data_name + \" PRIMARY KEY (example_id)\"\n",
    "        DBobj.create_table(data_name, fields, constraint)\n",
    "        \n",
    "        for i in range(rows):\n",
    "            matcher = []\n",
    "            matcher.append((\"example_id\", \"varchar\", str(i)))\n",
    "            fields = []\n",
    "            fields.append((\"example_id\", 'varchar', str(i)))\n",
    "            if data.ndim == 1:\n",
    "                value = [data[i]]\n",
    "            else:\n",
    "                value = data[i].tolist()\n",
    "            value = json.dumps(value)\n",
    "            fields.append((\"features\", \"varchar\", value))\n",
    "            DBobj.upsert(data_name, fields, matcher)\n",
    "        DBobj.close_db()\n",
    "        \n",
    "    def do_read(self, data_name):\n",
    "        if not isinstance(data_name, basestring):\n",
    "            raise MLException()\n",
    "        \n",
    "        DBobj = db.PGDBLib(MLRoot.db_password, MLRoot.db_host, MLRoot.db_port)\n",
    "        DBobj.open_db(MLRoot.db_tmo)   \n",
    "        \n",
    "        fields = []\n",
    "        fields.append((\"example_id\", \"varchar\", None))\n",
    "        fields.append((\"features\", \"varchar\", None))\n",
    "        row_list = DBobj.get_rows(data_name, fields, None) \n",
    "        nrows = len(row_list)\n",
    "        if nrows < 1:\n",
    "            raise MLException()\n",
    "        some_row = row_list[0]\n",
    "                          \n",
    "        # Two extra fields are added by PGDBLib\n",
    "        nfields = len(some_row) - 2 \n",
    "        if nfields != 2:\n",
    "            raise MLException()\n",
    "            \n",
    "        ncols = len(json.loads(some_row[3]))\n",
    "        if ncols == 1:\n",
    "            data = np.empty(shape=(nrows))\n",
    "        else:\n",
    "            data = np.empty(shape=(nrows, ncols))\n",
    "    \n",
    "        for i in range(nrows):\n",
    "            row = int(row_list[i][2])\n",
    "            value = json.loads(row_list[i][3])\n",
    "            if ncols == 1:\n",
    "                data[row] = value[0]\n",
    "            else:\n",
    "                data[row,:] = value\n",
    "        \n",
    "        DBobj.close_db()     \n",
    "        return data\n",
    "    \n",
    "    def do_delete(self, data_name):\n",
    "        return\n",
    "        if not isinstance(data_name, basestring):\n",
    "            raise MLException()\n",
    "        \n",
    "        DBobj = db.PGDBLib(MLRoot.db_password, MLRoot.db_host, MLRoot.db_port)\n",
    "        DBobj.open_db(MLRoot.db_tmo) \n",
    "        \n",
    "        DBobj.delete_rows(data_name, [])\n",
    "        \n",
    "        DBobj.drop_table(data_name)\n",
    "        \n",
    "        DBobj.close_db()\n",
    "    \n",
    "    @staticmethod\n",
    "    def init_storage(password, host=\"localhost\", port=\"5432\"):\n",
    "        db_password = password\n",
    "        db_host = host\n",
    "        db_port = port\n",
    "        db_tmo = 40000 * 3600 # 40 hours\n",
    "        DBobj = db.PGDBLib(password, host, port)\n",
    "        DBobj.create_db()\n",
    "        DBobj.open_db(db_tmo)\n",
    "        DBobj.close_db()\n",
    "    \n",
    "    @staticmethod\n",
    "    def destroy_storage():\n",
    "        db_password = None\n",
    "        db_host = None\n",
    "        db_port = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLFetch(MLRoot):\n",
    "    def __init__(self):\n",
    "        super(MLFetch, self).__init__()\n",
    "        self.class_name = \"MLFetch\"\n",
    "        self.max_size = None\n",
    "             \n",
    "        input_data = {\"remote_loc\" : \"\"}\n",
    "        input_json = json.dumps(input_data)\n",
    "        output_data = {\"final_loc\" : \"\" }\n",
    "        output_json = json.dumps(output_data)\n",
    "        \n",
    "        self.istr_jsons = input_json\n",
    "        self.ostr_jsons = output_json\n",
    "        \n",
    "    def do_run(self, input_data, traversal):\n",
    "        if traversal == \"POST\":\n",
    "            if not \"final_loc\" in input_data.keys():\n",
    "                input_data[\"final_loc\"] = \"\"\n",
    "            return input_data\n",
    "        dprint(DPRINT_INFO, self.name + \": Fetching data from: \" + input_data[\"remote_loc\"])\n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLDerive(MLRoot):\n",
    "    def __init__(self):\n",
    "        super(MLDerive, self).__init__()\n",
    "        self.class_name = \"MLDerive\"\n",
    "        self.X_map = None\n",
    "        self.y_map = None\n",
    "        \n",
    "        input_data = {\"final_loc\" : \"\"}\n",
    "        input_json = json.dumps(input_data)\n",
    "        output_data = {\"features\" : \"\"}\n",
    "        output_json = json.dumps(output_data)\n",
    "        \n",
    "        self.istr_jsons = input_json\n",
    "        self.ostr_jsons = output_json\n",
    "        \n",
    "    def do_walk(self, filepath, arg):\n",
    "          self.one_X_y(filepath, arg[\"extract_func\"], arg[\"arg\"], arg[\"X\"], arg[\"y\"])\n",
    "        \n",
    "    def one_X_y(self, filepath, extract_func, arg, X, y):\n",
    "        data = extract_func(filepath)\n",
    "        \n",
    "        features = np.zeros(shape=(len(self.X_map)))\n",
    "        labels = np.zeros(shape=(len(self.y_map)))\n",
    "        \n",
    "        for j, k in enumerate(self.y_map):\n",
    "            labels[j] = data[k]\n",
    "        for j, k in enumerate(self.X_map):\n",
    "            features[j] = data[k]\n",
    "        \n",
    "        X.append(features)\n",
    "        y.append(labels)\n",
    "            \n",
    "    def extract_X_y(self, extract_func, arg, file_spec):\n",
    "        # Label cannot also be in feature list\n",
    "        for label in self.y_map:\n",
    "            if label in self.X_map:\n",
    "                raise MLException()\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        if isinstance(file_spec, basestring):\n",
    "            arg[\"extract_func\"] = extract_func\n",
    "            arg[\"arg\"] = arg\n",
    "            arg[\"X\"] = X\n",
    "            arg[\"y\"] = y\n",
    "            self.do_walk(file_spec, arg)\n",
    "        elif isinstance(file_spec, list):\n",
    "            for fpath in file_spec:\n",
    "                self.one_X_y(fpath, extract_func, arg, X, y)\n",
    "        else:\n",
    "            raise MLException()\n",
    "            \n",
    "        if len(X) != len(y):\n",
    "            raise MLException()\n",
    "            \n",
    "        Xarray = np.empty(shape=(len(X), len(self.X_map)))\n",
    "        yarray = np.empty(shape=(len(y), len(self.y_map)))\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            Xarray[i,:] = X[i]\n",
    "        for i in range(len(y)):\n",
    "            yarray[i,:] = y[i]\n",
    "            \n",
    "        return Xarray, yarray\n",
    "    \n",
    "    def do_run(self, input_data, traversal):\n",
    "        if traversal == \"POST\":\n",
    "            if not \"features\" in input_data.keys():\n",
    "                input_data[\"features\"] = \"\"\n",
    "            return input_data\n",
    "        \n",
    "        dprint(DPRINT_INFO, self.name + \": Deriving Features from: \" + input_data['final_loc'])\n",
    "        \n",
    "        self.final_loc = input_data['final_loc']\n",
    "        \n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLModel(MLRoot):\n",
    "    def __init__(self):\n",
    "        super(MLModel, self).__init__()\n",
    "        self.class_name = \"MLModel\"\n",
    "        \n",
    "        input_data = {\"features\" : \"\"}\n",
    "        input_json = json.dumps(input_data)\n",
    "        output_data = {\"model\" : \"\"}\n",
    "        output_json = json.dumps(output_data)\n",
    "        \n",
    "        self.istr_jsons = input_json\n",
    "        self.ostr_jsons = output_json\n",
    "        \n",
    "    def do_run(self, input_data, traversal):\n",
    "        if traversal == \"POST\":\n",
    "            if not \"model\" in input_data.keys():\n",
    "                input_data[\"model\"] = \"\"\n",
    "            return input_data\n",
    "        dprint(DPRINT_INFO, self.name + \": Modelling... \")\n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLIngest(MLFetch):\n",
    "    def __init__(self):\n",
    "        super(MLIngest, self).__init__()\n",
    "        self.class_name = \"MLIngest\"\n",
    "        \n",
    "        input_data = {\"remote_loc\" : \"\"}\n",
    "        input_json = json.dumps(input_data)\n",
    "        output_data = {\"fetch_protocol\" : \"\", \"download_loc\" : \"\"}\n",
    "        output_json = json.dumps(output_data)\n",
    "        \n",
    "        self.istr_jsons = input_json\n",
    "        self.ostr_jsons = output_json\n",
    "        \n",
    "    def do_run(self, input_data, traversal):\n",
    "        \n",
    "        if traversal == \"POST\":\n",
    "            if not \"download_loc\" in input_data.keys():\n",
    "                input_data[\"download_loc\"] = \"\"\n",
    "            return input_data\n",
    "        \n",
    "        inloc = input_data[\"remote_loc\"]\n",
    "        \n",
    "        if inloc.startswith(\"http://\") or inloc.startswith(\"https://\"):\n",
    "            fetch_protocol = \"HTTP\"\n",
    "        elif os.path.exists(inloc) and (os.path.isfile(inloc) or os.path.isdir(inloc)):\n",
    "            fetch_protocol = \"LOCAL_FS\"\n",
    "        else:\n",
    "            # We can't handle this \n",
    "            raise MLException()\n",
    "            \n",
    "        input_data[\"fetch_protocol\"] = fetch_protocol\n",
    "        \n",
    "        # We don't prune nodes in the walk as this makes static checking (compile) difficult\n",
    "        return input_data\n",
    "        \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLHttpDownload(MLIngest):\n",
    "    def __init__(self):\n",
    "        super(MLHttpDownload, self).__init__()\n",
    "        self.class_name = \"MLHttpDownload\"\n",
    "        self.download_loc = None\n",
    "        \n",
    "        input_data = {\"remote_loc\" : \"\", \"fetch_protocol\" : \"\"}\n",
    "        input_json = json.dumps(input_data)\n",
    "        output_data = {\"download_loc\" : \"\"}\n",
    "        output_json = json.dumps(output_data)\n",
    "        \n",
    "        self.istr_jsons = input_json\n",
    "        self.ostr_jsons = output_json\n",
    "        \n",
    "    def do_run(self, input_data, traversal):\n",
    "        \n",
    "        if traversal == \"POST\":\n",
    "            if not \"download_loc\" in input_data.keys():\n",
    "                input_data[\"download_loc\"] = \"\"\n",
    "            return input_data\n",
    "        \n",
    "        if input_data[\"fetch_protocol\"] != \"HTTP\":\n",
    "            # We can't handle this. Pass it on, someone else may be able to\n",
    "            # XXX find a way so we dont have to add null properties\n",
    "            input_data[\"download_loc\"] = \"\"\n",
    "            return input_data\n",
    "        \n",
    "        self.download_loc = str(np.random.randint(randint_limit)) + \".download\"\n",
    "        input_data[\"download_loc\"] = self.download_loc\n",
    "        dprint(DPRINT_INFO, \n",
    "               self.name + \": Downloading HTTP data from: \" + input_data[\"remote_loc\"] + \" to \" + input_data[\"download_loc\"])\n",
    "           \n",
    "        url = input_data[\"remote_loc\"]\n",
    "        local_dest = input_data[\"download_loc\"]\n",
    "        # Check that the local destination's directory exists and is writable\n",
    "        try:\n",
    "            dirpath = os.path.dirname(local_dest)\n",
    "            with open(local_dest, \"wb\") as ofd:\n",
    "                pass\n",
    "            safe_rmtree(local_dest)\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "            \n",
    "        try:\n",
    "            r = requests.head(url)\n",
    "            if r.status_code != requests.codes.ok:\n",
    "                raise MLException()\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "            \n",
    "        try:\n",
    "            src_size = r.headers['Content-Length']\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "            \n",
    "        src_size_GB = src_size / (1024.0 * 1024.0 * 1024.0)\n",
    "        \n",
    "        if src_size_GB > self.max_size:\n",
    "            raise MLException()\n",
    "        \n",
    "        try:\n",
    "            r = requests.get(url, stream=True)\n",
    "            if r.status_code != requests.codes.ok:\n",
    "                raise MLException()\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "        \n",
    "        try:\n",
    "            with open(local_dest, 'wb') as fd:\n",
    "                # Use 8K chunk size\n",
    "                for chunk in r.iter_content(fetch_data_chunksize__):\n",
    "                    fd.write(chunk)\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "        \n",
    "        self.raw_size = src_size_GB\n",
    "        \n",
    "        return input_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLFSDownload(MLIngest):\n",
    "    def __init__(self):\n",
    "        super(MLFSDownload, self).__init__()\n",
    "        self.class_name = \"MLFSDownload\"\n",
    "        self.download_loc = None\n",
    "        \n",
    "        input_data = {\"remote_loc\" : \"\", \"fetch_protocol\" : \"\"}\n",
    "        input_json = json.dumps(input_data)\n",
    "        output_data = {\"download_loc\" : \"\"}\n",
    "        output_json = json.dumps(output_data)\n",
    "        \n",
    "        self.istr_jsons = input_json\n",
    "        self.ostr_jsons = output_json\n",
    "     \n",
    "        \n",
    "    def do_run(self, input_data, traversal):\n",
    "        \n",
    "        if traversal == \"POST\":\n",
    "            if not \"download_loc\" in input_data.keys():\n",
    "                input_data[\"download_loc\"] = \"\"\n",
    "            return input_data\n",
    "\n",
    "        # First check if we handle this data\n",
    "        if input_data[\"fetch_protocol\"] != \"LOCAL_FS\":\n",
    "            return input_data\n",
    "        \n",
    "        # First check if the local_src exists\n",
    "        local_src = input_data[\"remote_loc\"]\n",
    "        if os.path.exists(local_src):\n",
    "            dprint(DPRINT_INFO, self.name + \": The local source (\" + local_src + \") exists.\")\n",
    "        else:\n",
    "            raise MLException()\n",
    "            \n",
    "        try:\n",
    "            src_size = os.path.getsize(local_src)\n",
    "            src_size_GB = src_size / (1024.0 * 1024.0 * 1024.0)\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLEXception()\n",
    "        \n",
    "        # XXX Need a better solution than raising exception - should stop the pipeline\n",
    "        if src_size_GB > self.max_size:\n",
    "            raise MLException()\n",
    "            \n",
    "        # Dont't move the data. Use local source as is\n",
    "        input_data[\"download_loc\"] = local_src\n",
    "        \n",
    "        return input_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLDecompress(MLFetch):\n",
    "    def __init__(self):\n",
    "        super(MLDecompress, self).__init__()\n",
    "        self.class_name = \"MLDecompress\"\n",
    "         \n",
    "        input_data = {\"download_loc\" : \"\"}\n",
    "        input_json = json.dumps(input_data)\n",
    "        output_data = {\"decompress_loc\" : \"\"}\n",
    "        output_json = json.dumps(output_data)\n",
    "        \n",
    "        self.istr_jsons = input_json\n",
    "        self.ostr_jsons = output_json\n",
    "        \n",
    "    def do_run(self, input_data, traversal):\n",
    "        \n",
    "        if traversal == \"POST\":\n",
    "            if not os.path.exists(self.decompress_loc) or not os.path.isdir(self.decompress_loc):\n",
    "                # No decompression happened\n",
    "                safe_rmtree(self.decompress_loc)\n",
    "                input_data[\"decompress_loc\"] = input_data[\"download_loc\"]\n",
    "            return input_data\n",
    "        \n",
    "        dprint(DPRINT_INFO, self.name + \": Decompressing: \" + input_data[\"download_loc\"])\n",
    "        self.decompress_loc = input_data[\"download_loc\"] + \".\" + str(np.random.randint(randint_limit)) + \".decompressed\"\n",
    "        input_data[\"decompress_loc\"] = self.decompress_loc\n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLZipDecompress(MLDecompress):\n",
    "    def __init__(self):\n",
    "        super(MLZipDecompress, self).__init__()\n",
    "        self.class_name = \"MLZipDecompress\"\n",
    "        self.mime_type = 'application/zip'\n",
    "        \n",
    "        # Inherits input and output schema from parent\n",
    "        \n",
    "    def do_walk(self, filepath, input_data):\n",
    "        mime_type = magic.from_file(filepath, mime=True)\n",
    "        if mime_type != self.mime_type:\n",
    "            return {\"stop\" : False}\n",
    "        \n",
    "        dprint(DPRINT_INFO, self.name + \": ZipDecompress: \" + filepath)\n",
    "        if not filepath.startswith(self.download_loc):\n",
    "            raise MLException()\n",
    "    \n",
    "        dest_suffix = filepath[len(self.download_loc):]\n",
    "    \n",
    "        if dest_suffix == \"\":\n",
    "            fname = os.path.basename(self.download_loc) + \".\" + str(np.random.randint(randint_limit)) + \".unzip\"\n",
    "            dest = os.path.join(self.decompress_loc, fname)\n",
    "        else:\n",
    "            subdir = os.path.dirname(dest_suffix)\n",
    "            fname = os.path.basename(dest_suffix) + \".\" + str(np.random.randint(randint_limit)) + \".unzip\"\n",
    "            if subdir == \"\":\n",
    "                dest = os.path.join(self.decompress_loc, fname)\n",
    "            else:\n",
    "                subdir = subdir.split(\"/\")\n",
    "                subdir = \"/\".join(subdir[1:])\n",
    "                dest = os.path.join(self.decompress_loc, subdir, fname) \n",
    "        \n",
    "        try:\n",
    "            os.makedirs(dest)\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "        \n",
    "        try:\n",
    "            z = zipfile.ZipFile(filepath)\n",
    "            z.extractall(dest)\n",
    "            z.close()\n",
    "        except:\n",
    "            debug_raise()\n",
    "            safe_rmtree(self.decompress_loc, ignore_errors=True)\n",
    "            raise MLException()\n",
    "            \n",
    "        return {\"stop\" : False}\n",
    "        \n",
    "    def do_run(self, input_data, traversal):\n",
    "        \n",
    "        if traversal == \"POST\":\n",
    "            if not \"decompress_loc\" in input_data.keys():\n",
    "                input_data[\"decompress_loc\"] = \"\"\n",
    "            return input_data\n",
    "        \n",
    "        self.download_loc = input_data[\"download_loc\"]\n",
    "        self.decompress_loc = input_data[\"decompress_loc\"]\n",
    "        self.walk_files(self.download_loc, input_data)\n",
    "        \n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLBzip2Decompress(MLDecompress):\n",
    "    def __init__(self):\n",
    "        super(MLBzip2Decompress, self).__init__()\n",
    "        self.class_name = \"MLBzip2Decompress\"\n",
    "        self.mime_type = 'application/x-bzip2'\n",
    "        \n",
    "        # Inherits input and output schema from parent\n",
    "      \n",
    "    def do_walk(self, filepath, input_data):\n",
    "        \n",
    "        mime_type = magic.from_file(filepath, mime=True)\n",
    "        \n",
    "        if mime_type != self.mime_type:\n",
    "            return {\"stop\" : False}\n",
    "        \n",
    "        dprint(DPRINT_INFO, self.name + \": Bzip2Decompress: \" + filepath)\n",
    "        if not filepath.startswith(self.download_loc):\n",
    "            raise MLException()\n",
    "            \n",
    "        dest_suffix = filepath[len(self.download_loc):]\n",
    "        \n",
    "        if dest_suffix == \"\":\n",
    "            fname = self.download_loc + \".\" + str(np.random.randint(randint_limit)) + \".bunzip2\"\n",
    "            fname = fname.split(\"/\")\n",
    "            fname = \"/\".join(fname[1:])\n",
    "            dest = os.path.join(self.decompress_loc, fname)\n",
    "        else:\n",
    "            subdir = os.path.dirname(dest_suffix)\n",
    "            fname = os.path.basename(dest_suffix) + \".\" + str(np.random.randint(randint_limit)) + \".bunzip2\"\n",
    "            if subdir == \"\":\n",
    "                dest = os.path.join(self.decompress_loc, fname)\n",
    "            else:\n",
    "                subdir = subdir.split(\"/\")\n",
    "                subdir = \"/\".join(subdir[1:])\n",
    "                dest = os.path.join(self.decompress_loc, subdir, fname) \n",
    "        \n",
    "        try:\n",
    "            os.makedirs(dest)\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "            \n",
    "        destfile = os.path.join(dest, \".file\")\n",
    "            \n",
    "        # XXX check for return MLException() instead of raise\n",
    "        try:\n",
    "            data = bz2.decompress(open(filepath, \"rb\").read())\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "        \n",
    "        try:\n",
    "            with open(destfile, \"wb\") as ofd:\n",
    "                ofd.write(data)\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "            \n",
    "        return {\"stop\" : False}\n",
    "        \n",
    "    def do_run(self, input_data, traversal):\n",
    "        if traversal == \"POST\":\n",
    "            if not \"decompress_loc\" in input_data.keys():\n",
    "                input_data[\"decompress_loc\"] = \"\"\n",
    "            return input_data\n",
    " \n",
    "        self.download_loc = input_data[\"download_loc\"]\n",
    "        self.decompress_loc = input_data[\"decompress_loc\"]\n",
    "        \n",
    "        self.walk_files(self.download_loc, input_data)\n",
    "    \n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLGzipDecompress(MLDecompress):\n",
    "    def __init__(self):\n",
    "        super(MLGzipDecompress, self).__init__()\n",
    "        self.class_name = \"MLGzipDecompress\"\n",
    "        self.mime_type = 'application/x-gzip'\n",
    "        \n",
    "        # Inherits input and output schema from parent\n",
    "      \n",
    "    def do_walk(self, filepath, input_data):\n",
    "        \n",
    "        mime_type = magic.from_file(filepath, mime=True)\n",
    "        if mime_type != self.mime_type:\n",
    "            return {\"stop\" : False}\n",
    "        \n",
    "        dprint(DPRINT_INFO, self.name + \": GzipDecompress: \" + filepath)\n",
    "        if not filepath.startswith(self.download_loc):\n",
    "            raise MLException()\n",
    "        \n",
    "        dest_suffix = filepath[len(self.download_loc):]\n",
    "        \n",
    "        if dest_suffix == \"\":\n",
    "            fname = self.download_loc + \".\" + str(np.random.randint(randint_limit)) + \".gunzip\"\n",
    "            fname = fname.split(\"/\")\n",
    "            fname = \"/\".join(fname[1:])\n",
    "            dest = os.path.join(self.decompress_loc, fname)\n",
    "        else:\n",
    "            subdir = os.path.dirname(dest_suffix)\n",
    "            fname = os.path.basename(dest_suffix) + \".\" + str(np.random.randint(randint_limit)) + \".gunzip\"\n",
    "            if subdir == \"\":\n",
    "                dest = os.path.join(self.decompress_loc, fname)\n",
    "            else:\n",
    "                subdir = subdir.split(\"/\")\n",
    "                subdir = \"/\".join(subdir[1:])\n",
    "                dest = os.path.join(self.decompress_loc, subdir, fname) \n",
    " \n",
    "        try:\n",
    "            os.makedirs(dest)\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "            \n",
    "        destfile = os.path.join(dest, \".file\")\n",
    "        \n",
    "        try:\n",
    "            with open(dest, \"wb\") as ofd:\n",
    "                with gzip.open(filepath, \"rb\") as cfd:\n",
    "                    while True:\n",
    "                        data = cfd.read(gunzip_blocksize_)\n",
    "                        if data == '':\n",
    "                            return {\"stop\" : False}\n",
    "                        ofd.write(data)\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "            \n",
    "        raise MLException()\n",
    "        \n",
    "    def do_run(self, input_data, traversal):\n",
    "        \n",
    "        if traversal == \"POST\":\n",
    "            if not \"decompress_loc\" in input_data.keys():\n",
    "                input_data[\"decompress_loc\"] = \"\"\n",
    "            return input_data\n",
    "        \n",
    "        self.download_loc = input_data[\"download_loc\"]\n",
    "        self.decompress_loc = input_data[\"decompress_loc\"]\n",
    "        \n",
    "        self.walk_files(self.download_loc, input_data)\n",
    "    \n",
    "        return input_data\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLUnarchive(MLFetch):\n",
    "    def __init__(self):\n",
    "        super(MLUnarchive, self).__init__()\n",
    "        self.class_name = \"MLUnarchive\"\n",
    "        self.mime_type = None\n",
    "        self.unarchive_loc = None\n",
    "        \n",
    "        input_data = {\"decompress_loc\" : \"\"}\n",
    "        input_json = json.dumps(input_data)\n",
    "        output_data = {\"unarchive_loc\" : \"\"}\n",
    "        output_json = json.dumps(output_data)\n",
    "        \n",
    "        self.istr_jsons = input_json\n",
    "        self.ostr_jsons = output_json\n",
    "        \n",
    "    def do_run(self, input_data, traversal):\n",
    "        \n",
    "        if traversal == \"POST\":\n",
    "            if not os.path.exists(self.unarchive_loc) or not os.path.isdir(self.unarchive_loc):\n",
    "                # No unarchiving happened\n",
    "                safe_rmtree(self.unarchive_loc)\n",
    "                input_data[\"unarchive_loc\"] = input_data[\"decompress_loc\"]\n",
    "            return input_data\n",
    "        \n",
    "        dprint(DPRINT_INFO, self.name + \": Unarchiving: \" + input_data[\"decompress_loc\"])\n",
    "        self.unarchive_loc = input_data[\"decompress_loc\"] + \".\" + str(np.random.randint(randint_limit)) + \".unarchived\"\n",
    "        input_data[\"unarchive_loc\"] = self.unarchive_loc\n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLTarUnarchive(MLUnarchive):\n",
    "    def __init__(self):\n",
    "        super(MLTarUnarchive, self).__init__()\n",
    "        self.class_name = \"MLTarUnarchive\"\n",
    "        self.mime_type = \"application/x-tar\"\n",
    "        \n",
    "        # Inherits input and output schema from parent\n",
    "    \n",
    "    \n",
    "    def do_walk(self, filepath, input_data):\n",
    "        \n",
    "        mime_type = magic.from_file(filepath, mime=True)\n",
    "        if mime_type != self.mime_type:\n",
    "            return {\"stop\" : False}\n",
    "        \n",
    "        dprint(DPRINT_INFO, self.name + \": Untar: \" + filepath)\n",
    "        \n",
    "        if not filepath.startswith(self.decompress_loc):\n",
    "            raise MLException()\n",
    "            \n",
    "        dest_suffix = filepath[len(self.decompress_loc):]\n",
    "        \n",
    "        if dest_suffix == \"\":\n",
    "            fname = self.download_loc + \".\" + str(np.random.randint(randint_limit)) + \".untar\"\n",
    "            fname = fname.split(\"/\")\n",
    "            fname = \"/\".join(fname[1:])\n",
    "            dest = os.path.join(self.unarchive_loc, fname)\n",
    "        else:\n",
    "            subdir = os.path.dirname(dest_suffix)\n",
    "            fname =  os.path.basename(dest_suffix) + \".\" + str(np.random.randint(randint_limit)) + \".untar\"\n",
    "            if subdir == \"\":\n",
    "                dest = os.path.join(self.unarchive_loc, fname)\n",
    "            else:\n",
    "                subdir = subdir.split(\"/\")\n",
    "                subdir = \"/\".join(subdir[1:])\n",
    "                dest = os.path.join(self.unarchive_loc, subdir, fname)\n",
    "        \n",
    "        try:\n",
    "            if not tarfile.is_tarfile(filepath):\n",
    "                raise MLException()\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "          \n",
    "        try:\n",
    "            tfile = tarfile.TarFile(filepath, \"r\")\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "        \n",
    "        try:\n",
    "            os.makedirs(dest)\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "            \n",
    "        try:\n",
    "            tfile.extractall(dest)\n",
    "        except:\n",
    "            debug_raise()\n",
    "            raise MLException()\n",
    "            \n",
    "        return {\"stop\" : False}\n",
    "\n",
    "        \n",
    "    def do_run(self, input_data, traversal):\n",
    "        \n",
    "        if traversal == \"POST\":\n",
    "            if not \"unarchive_loc\" in input_data.keys():\n",
    "                input_data[\"unarchive_loc\"] = \"\"\n",
    "            return input_data\n",
    "            \n",
    "        self.decompress_loc = input_data[\"decompress_loc\"]\n",
    "        self.unarchive_loc = input_data[\"unarchive_loc\"]\n",
    "        \n",
    "        self.walk_files(self.decompress_loc, input_data)\n",
    "        \n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLRaw(MLFetch):\n",
    "    def __init__(self):\n",
    "        super(MLRaw, self).__init__()\n",
    "        self.class_name = \"MLRaw\"\n",
    "        self.final_loc = None\n",
    "        \n",
    "        input_data = {\"unarchive_loc\" : \"\"}\n",
    "        input_json = json.dumps(input_data)\n",
    "        output_data = {\"final_loc\" : \"\"}\n",
    "        output_json = json.dumps(output_data)\n",
    "        \n",
    "        self.istr_jsons = input_json\n",
    "        self.ostr_jsons = output_json\n",
    "        \n",
    "    def do_run(self, input_data, traversal):\n",
    "        \n",
    "        if traversal == \"POST\":\n",
    "            if not \"final_loc\" in input_data.keys():\n",
    "                input_data[\"final_loc\"] = \"\"\n",
    "            return input_data\n",
    "        \n",
    "        dprint(DPRINT_INFO, self.name + \": Raw data processing from: \" + input_data[\"unarchive_loc\"])\n",
    "    \n",
    "        self.final_loc = input_data[\"final_loc\"] = input_data[\"unarchive_loc\"]\n",
    "        \n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SampleExtractFeatures(MLDerive):\n",
    "    def __init__(self):\n",
    "        super(SampleExtractFeatures, self).__init__()\n",
    "        self.class_name = \"SampleExtractFeatures\"\n",
    "        self.mime_type = 'text/plain'  \n",
    "        self.final_loc = None\n",
    "        self.data_name = None\n",
    "        \n",
    "        input_data = {\"final_loc\" : \"\"}\n",
    "        input_json = json.dumps(input_data)\n",
    "        output_data = {\"Xtrain\" : \"\", \"ytrain\" : \"\", \"Xtest\" : \"\", \"ytest\" : \"\"}\n",
    "        output_json = json.dumps(output_data)    \n",
    "        \n",
    "        self.istr_jsons = input_json\n",
    "        self.ostr_jsons = output_json\n",
    "        \n",
    "    def sample_extract(self, filepath):\n",
    "            \n",
    "        df = pd.read_csv(filepath, header=0)\n",
    "            \n",
    "        y = df.iloc[:,0].copy()\n",
    "        X = df.iloc[:,1:].copy()\n",
    "        \n",
    "        X = X.values\n",
    "        y = y.values\n",
    "\n",
    "        dprint(DPRINT_INFO, filepath + \": X.shape=\" + str(X.shape) + \", y.shape=\" + str(y.shape))\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "    def do_walk(self, filepath, input_data):\n",
    "        if get_file_type(filepath, mime=True) != self.mime_type:\n",
    "            raise MLException()\n",
    "            \n",
    "        if os.path.basename(filepath) == \"sample_train_data.csv\":\n",
    "            input_data[\"Xtrain\"], input_data[\"ytrain\"] = self.sample_extract(filepath)\n",
    "            self.do_save(self.data_name + \"_Xtrain\", input_data[\"Xtrain\"])\n",
    "            self.do_save(self.data_name + \"_ytrain\", input_data[\"ytrain\"])\n",
    "            input_data[\"Xtrain\"] = self.data_name + \"_Xtrain\"\n",
    "            input_data[\"ytrain\"] = self.data_name + \"_ytrain\"\n",
    "        elif os.path.basename(filepath) == \"sample_test_data.csv\":\n",
    "            input_data[\"Xtest\"], input_data[\"ytest\"] = self.sample_extract(filepath)\n",
    "            self.do_save(self.data_name + \"_Xtest\", input_data[\"Xtest\"])\n",
    "            self.do_save(self.data_name + \"_ytest\", input_data[\"ytest\"])\n",
    "            input_data[\"Xtest\"] = self.data_name + \"_Xtest\"\n",
    "            input_data[\"ytest\"] = self.data_name + \"_ytest\"\n",
    "        else:\n",
    "            raise MLException()\n",
    "            \n",
    "        return {\"stop\" : False}\n",
    "            \n",
    "    def do_run(self, input_data, traversal):\n",
    "        if traversal == \"POST\":\n",
    "            if not \"Xtrain\" in input_data.keys():\n",
    "                input_data[\"Xtrain\"] = \"\"\n",
    "            if not \"ytrain\" in input_data.keys():\n",
    "                input_data[\"ytrain\"] = \"\"\n",
    "            if not \"Xtest\" in input_data.keys():\n",
    "                input_data[\"Xtest\"] = \"\"\n",
    "            if not \"ytest\" in input_data.keys():\n",
    "                input_data[\"ytest\"] = \"\"\n",
    "            return input_data\n",
    "         \n",
    "        if self.data_name is None or not isinstance(self.data_name, basestring):\n",
    "            raise MLException()\n",
    "            \n",
    "        # Data names cannot have \".\" in them, a limitation of the storage subsystem.\n",
    "        if \".\" in self.data_name:\n",
    "            raise MLException()\n",
    "            \n",
    "        self.final_loc = input_data['final_loc']\n",
    "        \n",
    "        self.walk_files(self.final_loc, input_data)\n",
    "        \n",
    "        return input_data\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
