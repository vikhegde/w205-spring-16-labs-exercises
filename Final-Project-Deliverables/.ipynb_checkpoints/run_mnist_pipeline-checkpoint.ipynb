{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from ml_pipeline import *\n",
    "from model_common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to process MNIST data follows this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExtractMNIST(MLDerive):\n",
    "    def __init__(self):\n",
    "        super(ExtractMNIST, self).__init__()\n",
    "        self.class_name = \"ExtractMNIST\"\n",
    "        self.mime_type = 'text/plain'  \n",
    "        self.final_loc = None\n",
    "        self.data_name = None\n",
    "        \n",
    "        input_data = {\"final_loc\" : \"\"}\n",
    "        input_json = json.dumps(input_data)\n",
    "        output_data = {\"Xtrain\" : \"\", \"ytrain\" : \"\", \"Xtest\" : \"\", \"ytest\" : \"\"}\n",
    "        output_json = json.dumps(output_data)    \n",
    "        \n",
    "        self.istr_jsons = input_json\n",
    "        self.ostr_jsons = output_json\n",
    "        \n",
    "    def extract_mnist(self, filepath):\n",
    "            \n",
    "        df = pd.read_csv(filepath, header=None)\n",
    "            \n",
    "        y = df.iloc[:,0].copy()\n",
    "        X = df.iloc[:,1:].copy()\n",
    "        \n",
    "        X = X.values\n",
    "        y = y.values\n",
    "        \n",
    "        # Normalize data to range [0,1]\n",
    "        X = X/255.0\n",
    "        #X = np.array([[1.1, 2.2],[3.3,4.4]])\n",
    "        #y = np.array([1,2])\n",
    "        dprint(DPRINT_INFO, filepath + \": X.shape=\" + str(X.shape) + \", y.shape=\" + str(y.shape))\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "    def do_walk(self, filepath, input_data):\n",
    "        if get_file_type(filepath, mime=True) != self.mime_type:\n",
    "            raise MLException()\n",
    "            \n",
    "        if os.path.basename(filepath) == \"mnist_train.csv\":\n",
    "            input_data[\"Xtrain\"], input_data[\"ytrain\"] = self.extract_mnist(filepath)\n",
    "            self.do_save(self.data_name + \"_Xtrain\", input_data[\"Xtrain\"])\n",
    "            self.do_save(self.data_name + \"_ytrain\", input_data[\"ytrain\"])\n",
    "            input_data[\"Xtrain\"] = self.data_name + \"_Xtrain\"\n",
    "            input_data[\"ytrain\"] = self.data_name + \"_ytrain\"\n",
    "        elif os.path.basename(filepath) == \"mnist_test.csv\":\n",
    "            input_data[\"Xtest\"], input_data[\"ytest\"] = self.extract_mnist(filepath)\n",
    "            self.do_save(self.data_name + \"_Xtest\", input_data[\"Xtest\"])\n",
    "            self.do_save(self.data_name + \"_ytest\", input_data[\"ytest\"])\n",
    "            input_data[\"Xtest\"] = self.data_name + \"_Xtest\"\n",
    "            input_data[\"ytest\"] = self.data_name + \"_ytest\"\n",
    "        else:\n",
    "            raise MLException()\n",
    "            \n",
    "        return {\"stop\" : False}\n",
    "            \n",
    "    def do_run(self, input_data, traversal):\n",
    "        if traversal == \"POST\":\n",
    "            if not \"Xtrain\" in input_data.keys():\n",
    "                input_data[\"Xtrain\"] = \"\"\n",
    "            if not \"ytrain\" in input_data.keys():\n",
    "                input_data[\"ytrain\"] = \"\"\n",
    "            if not \"Xtest\" in input_data.keys():\n",
    "                input_data[\"Xtest\"] = \"\"\n",
    "            if not \"ytest\" in input_data.keys():\n",
    "                input_data[\"ytest\"] = \"\"\n",
    "            return input_data\n",
    "         \n",
    "        if self.data_name is None or not isinstance(self.data_name, basestring):\n",
    "            raise MLException()\n",
    "            \n",
    "        # Postgres does not like \".\" in table names\n",
    "        if \".\" in self.data_name:\n",
    "            raise MLException()\n",
    "            \n",
    "        self.final_loc = input_data['final_loc']\n",
    "        \n",
    "        self.walk_files(self.final_loc, input_data)\n",
    "        \n",
    "        return input_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes on the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(INFO)creating node: resource: MLFetch, mount_subtree: /root/fetch\n",
      "(INFO)creating node: resource: MLDerive, mount_subtree: /root/derive\n",
      "(INFO)creating node: resource: MLModel, mount_subtree: /root/model\n",
      "(INFO)creating node: resource: MLIngest, mount_subtree: /fetch/ingest\n",
      "(INFO)creating node: resource: MLDecompress, mount_subtree: /fetch/decompress\n",
      "(INFO)creating node: resource: MLUnarchive, mount_subtree: /fetch/unarchive\n",
      "(INFO)creating node: resource: MLRaw, mount_subtree: /fetch/raw\n",
      "(INFO)creating node: resource: MLHttpDownload, mount_subtree: /ingest/http_download\n",
      "(INFO)creating node: resource: MLFSDownload, mount_subtree: /ingest/fs_download\n",
      "(INFO)creating node: resource: MLZipDecompress, mount_subtree: /decompress/zip_decompress\n",
      "(INFO)creating node: resource: MLBzip2Decompress, mount_subtree: /decompress/bzip2_decompress\n",
      "(INFO)creating node: resource: MLGzipDecompress, mount_subtree: /decompress/gzip_decompress\n",
      "(INFO)creating node: resource: MLTarUnarchive, mount_subtree: /unarchive/tar_unarchive\n",
      "(INFO)creating node: resource: ExtractMNIST, mount_subtree: /derive/mnist_extract\n",
      "(INFO)creating node: resource: BernNB, mount_subtree: /model/mnist_bernNB\n",
      "(DEBUG)fetch: path: /root/fetch\n",
      "(DEBUG)ingest: path: /root/fetch/ingest\n",
      "(DEBUG)http_download: path: /root/fetch/ingest/http_download\n",
      "(DEBUG)fs_download: path: /root/fetch/ingest/fs_download\n",
      "(DEBUG)decompress: path: /root/fetch/decompress\n",
      "(DEBUG)zip_decompress: path: /root/fetch/decompress/zip_decompress\n",
      "(DEBUG)bzip2_decompress: path: /root/fetch/decompress/bzip2_decompress\n",
      "(DEBUG)gzip_decompress: path: /root/fetch/decompress/gzip_decompress\n",
      "(DEBUG)unarchive: path: /root/fetch/unarchive\n",
      "(DEBUG)tar_unarchive: path: /root/fetch/unarchive/tar_unarchive\n",
      "(DEBUG)raw: path: /root/fetch/raw\n",
      "(DEBUG)derive: path: /root/derive\n",
      "(DEBUG)mnist_extract: path: /root/derive/mnist_extract\n",
      "(DEBUG)model: path: /root/model\n",
      "(DEBUG)mnist_bernNB: path: /root/model/mnist_bernNB\n",
      "(DEBUG)compile: root\n",
      "(DEBUG)do_compile: root\n",
      "(DEBUG)compile: fetch\n",
      "(DEBUG)do_compile: fetch\n",
      "(DEBUG)compile: ingest\n",
      "(DEBUG)do_compile: ingest\n",
      "(DEBUG)compile: http_download\n",
      "(DEBUG)do_compile: http_download\n",
      "(DEBUG)compile: fs_download\n",
      "(DEBUG)do_compile: fs_download\n",
      "(DEBUG)compile: decompress\n",
      "(DEBUG)do_compile: decompress\n",
      "(DEBUG)compile: zip_decompress\n",
      "(DEBUG)do_compile: zip_decompress\n",
      "(DEBUG)compile: bzip2_decompress\n",
      "(DEBUG)do_compile: bzip2_decompress\n",
      "(DEBUG)compile: gzip_decompress\n",
      "(DEBUG)do_compile: gzip_decompress\n",
      "(DEBUG)compile: unarchive\n",
      "(DEBUG)do_compile: unarchive\n",
      "(DEBUG)compile: tar_unarchive\n",
      "(DEBUG)do_compile: tar_unarchive\n",
      "(DEBUG)compile: raw\n",
      "(DEBUG)do_compile: raw\n",
      "(DEBUG)compile: derive\n",
      "(DEBUG)do_compile: derive\n",
      "(DEBUG)compile: mnist_extract\n",
      "(DEBUG)do_compile: mnist_extract\n",
      "(DEBUG)compile: model\n",
      "(DEBUG)do_compile: model\n",
      "(DEBUG)compile: mnist_bernNB\n",
      "(DEBUG)do_compile: mnist_bernNB\n",
      "(INFO)root: RUN: NULL_ACTION: traversal: PRE\n",
      "(INFO)fetch: Fetching data from: /data/mnist_original.zip\n",
      "(INFO)fs_download: The local source (/data/mnist_original.zip) exists.\n",
      "(INFO)decompress: Decompressing: /data/mnist_original.zip\n",
      "/data/mnist_original.zip.588396.decompressed\n",
      "/data/mnist_original.zip.588396.decompressed\n",
      "(INFO)zip_decompress: ZipDecompress: /data/mnist_original.zip\n",
      "(INFO)unarchive: Unarchiving: /data/mnist_original.zip.588396.decompressed\n",
      "(INFO)raw: Raw data processing from: /data/mnist_original.zip.588396.decompressed\n",
      "(INFO)derive: Deriving Features from: /data/mnist_original.zip.588396.decompressed\n",
      "(INFO)/data/mnist_original.zip.588396.decompressed/mnist_original.zip.123336.unzip/mnist_test.csv: X.shape=(10000, 784), y.shape=(10000,)\n",
      "(INFO)/data/mnist_original.zip.588396.decompressed/mnist_original.zip.123336.unzip/mnist_train.csv: X.shape=(60000, 784), y.shape=(60000,)\n",
      "(INFO)model: Modelling... \n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[ 5.  0.  4. ...,  5.  6.  8.]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[ 7.  2.  1. ...,  4.  5.  6.]\n",
      "(INFO)Bernoulli Naive Bayes: \n",
      "(INFO)\t\tAccuracy for: 5 samples is: 0.3201\n",
      "(INFO)\t\tAccuracy for: 10 samples is: 0.1702\n",
      "(INFO)\t\tAccuracy for: 20 samples is: 0.2489\n",
      "(INFO)\t\tAccuracy for: 50 samples is: 0.4925\n",
      "(INFO)\t\tAccuracy for: 100 samples is: 0.6149\n",
      "(INFO)\t\tAccuracy for: 250 samples is: 0.7101\n",
      "(INFO)\t\tAccuracy for: 500 samples is: 0.7535\n",
      "(INFO)\t\tAccuracy for: 1000 samples is: 0.7945\n",
      "(INFO)\t\tAccuracy for: 5000 samples is: 0.8357\n",
      "(INFO)\t\tAccuracy for: 10000 samples is: 0.8371\n",
      "(INFO)\t\tAccuracy for: 20000 samples is: 0.8409\n",
      "(INFO)\t\tAccuracy for: 30000 samples is: 0.8454\n",
      "(INFO)\t\tAccuracy for: 40000 samples is: 0.8441\n",
      "(INFO)model: Modelling... \n",
      "(INFO)Freeing node: name: fs_download,class: MLFSDownload\n",
      "(INFO)Freeing node: name: http_download,class: MLHttpDownload\n",
      "(INFO)Freeing node: name: gzip_decompress,class: MLGzipDecompress\n",
      "(INFO)Freeing node: name: bzip2_decompress,class: MLBzip2Decompress\n",
      "(INFO)Freeing node: name: zip_decompress,class: MLZipDecompress\n",
      "(INFO)Freeing node: name: tar_unarchive,class: MLTarUnarchive\n",
      "(INFO)Freeing node: name: raw,class: MLRaw\n",
      "(INFO)Freeing node: name: unarchive,class: MLUnarchive\n",
      "(INFO)Freeing node: name: decompress,class: MLDecompress\n",
      "(INFO)Freeing node: name: ingest,class: MLIngest\n",
      "(INFO)Freeing node: name: mnist_extract,class: ExtractMNIST\n",
      "(INFO)Freeing node: name: mnist_bernNB,class: BernNB\n",
      "(INFO)Freeing node: name: model,class: MLModel\n",
      "(INFO)Freeing node: name: derive,class: MLDerive\n",
      "(INFO)Freeing node: name: fetch,class: MLFetch\n",
      "(INFO)Freeing node: name: root,class: MLRoot\n"
     ]
    }
   ],
   "source": [
    "nsamples_list = [5, 10, 20, 50, 100, 250, 500, 1000, 5000, 10000, 20000, 30000, 40000]\n",
    "MLRoot.init_storage(password=\"xypostgres\", host=\"localhost\", port=\"5432\")\n",
    "\n",
    "#nsamples_list = [5, 10]\n",
    "myML = MLRoot()\n",
    "myML.mount(mount_spec = \"./mnist_bernNB_mounts.json\")\n",
    "myML.print_tree()\n",
    "input_data = {}\n",
    "input_data[\"remote_loc\"] = \"\"\n",
    "myML.compile(json.dumps(input_data))\n",
    "input_data[\"remote_loc\"] = \"/data/mnist_original.zip\"\n",
    "myML.setprop(\"/root/fetch\", {\"max_size\" : 1000})\n",
    "myML.setprop(\"/root/derive/mnist_extract\", {\"data_name\" : \"bernNB\"})\n",
    "myML.setprop(\"/root/model/mnist_bernNB\", {\"nsamples_list\" : nsamples_list})\n",
    "myML.run(input_data)\n",
    "myML.umount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myML = MLRoot()\n",
    "myML.mount(mount_spec = \"./mnist_logistic_mounts.json\")\n",
    "myML.print_tree()\n",
    "input_data = {}\n",
    "input_data[\"remote_loc\"] = \"\"\n",
    "myML.compile(json.dumps(input_data))\n",
    "input_data[\"remote_loc\"] = \"mnist_original.zip\"\n",
    "myML.setprop(\"/root/fetch\", {\"max_size\" : 1000})\n",
    "myML.setprop(\"/root/derive/mnist_extract\", {\"data_name\" : \"Logistic\"})\n",
    "myML.setprop(\"/root/model/mnist_logistic\", {\"nsamples_list\" : nsamples_list})\n",
    "myML.run(input_data)\n",
    "myML.umount()\n",
    "\n",
    "MLRoot.destroy_storage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
